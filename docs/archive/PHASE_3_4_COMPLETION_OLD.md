# MSR India TAB MVP vs. Phase 2 Feature Tracking

**Last Updated**: January 15, 2026  
**Launch Target**: MSR India TAB (Late January 2026)  
**Owner**: Peter (Chat Logic) + Mike (Frontend/Bookmarks)

---

## üéØ INDIA MVP SCOPE (What Blocks Launch)

Based on BRD Section 6 & Compliance Gates, the India MVP requires:

### ‚úÖ Already Done
- ‚úÖ 15 chat actions (browse, filter, search, navigation, experiences)
- ‚úÖ Streaming responses with Azure OpenAI
- ‚úÖ Telemetry framework (1DS instrumented)
- ‚úÖ Event data layer (repositories, CRUD)
- ‚úÖ Hourly agenda & presenter carousel handlers

### ‚è≥ INDIA BLOCKING (Must Complete Before Launch)
- **DOSA Design Compliance**: Document fail-closed architecture (cites only) in RAI Impact Assessment
- **Minimal Refusal Logging**: Basic capability to log when AI refuses (code + telemetry)
- **Compliance Sign-Offs**: RAI Inventory, HR Legal, DPIA, Accessibility, Security, SSPA (org/process items)
- **Continuous Compliance Plan**: Document monitoring strategy (refusal rate, edit %, incident escalation)

### üö´ NOT BLOCKING INDIA (Defer to Phase 2)
- ‚ùå Advanced governance enforcement (`governance_enforcer.py` with policy blocking)
- ‚ùå Complex edit tracking dashboard
- ‚ùå Multi-event discovery enhancement
- ‚ùå Bookmark backend persistence *(Mike's scope; functional stub is OK for MVP)*
- ‚ùå PKA synthesis agents (Phase 2+, already blocked from attendee surfaces)

---

## UPDATED FEATURES (Existing, Need Enhancement)

| Story ID | Feature Name | Summary | Owner | Status | Priority | Target Date | Description |
|---|---|---|---|---|---|---|---|
| DOSA-001 | Base chat/copilot (DOSA) | Implement DOSA fail-closed contract | Peter | ‚è≥ In Progress | **CRITICAL** | **Jan 24, 2026** *(India MVP)* | Validate citations-required, block inference; add refusal tracking; implement edit logging for compliance metrics |
| BOOKMARK-001 | Bookmark list & post-event access | Complete backend persistence for bookmarks | Mike | ‚è≥ In Progress | **HIGH** | **Jan 24, 2026** *(India MVP)* | Create bookmark table, implement create/retrieve/delete endpoints, wire action handler to database |
| TELEMETRY-001 | Adobe Analytics 1DS Configuration | Add governance & compliance metrics | Peter | ‚è≥ In Progress | **HIGH** | **Jan 24, 2026** *(India MVP)* | Add refusal rate tracking, edit percentage, compliance readiness indicators; ensure `copilot_interaction` events capture DOSA compliance data |
| ANALYTICS-002 | Pre-event unique users | Telemetry for pre-event visits | Analytics Team | üìã Planned | **MEDIUM** | **Mar 3, 2026** *(Phase 2)* | Emit pre-event visit events (user_visit, session_start); backend aggregation for reporting |
| ANALYTICS-003 | Post-event unique users | Telemetry for post-event visits | Analytics Team | üìã Planned | **MEDIUM** | **Mar 3, 2026** *(Phase 2)* | Emit post-event visit events; 7/30-day follow-up tracking |
| ANALYTICS-004 | Extended-reach users | Geolocation & regional tracking | Analytics Team | üìã Planned | **MEDIUM** | **Mar 3, 2026** *(Phase 2)* | Add geolocation tracking; aggregate by timezone/region |
| ANALYTICS-005 | Platform KPIs | Emit platform-level metrics | Analytics Team | üìã Planned | **MEDIUM** | **Mar 3, 2026** *(Phase 2)* | Emit: events_onboarded, repeat_usage, organizer_self_service_rate, post_event_content_usage, cross_event_engagement |
| ANALYTICS-006 | Connections/leads initiated | Track engagement actions | Analytics Team | üìã Planned | **MEDIUM** | **Mar 3, 2026** *(Phase 2)* | Track: email_click, repo_visit, asset_download events; aggregate into leads/connections count |

## NEW FEATURES (Need Implementation)

| Story ID | Feature Name | Summary | Owner | Status | Priority | Target Date | Description |
|---|---|---|---|---|---|---|---|
| GOV-002 | AI Refusal Tracking & Metrics | Governance compliance telemetry | Peter | ‚è≥ In Progress | **CRITICAL** | **Jan 24, 2026** *(India MVP)* | Implement `log_refusal()` in telemetry module; track: refusal_reason, query_context, handler_name; create dashboard aggregation |
| GOV-003 | Edit Percentage Logging | Human-in-loop compliance metric | Peter | ‚è≥ In Progress | **HIGH** | **Jan 24, 2026** *(India MVP)* | Implement `log_edit_event()` in telemetry; track when user edits AI output vs. accepts; send to 1DS for monthly reporting |
| DISCOVERY-001 | Multi-Event Discovery Enhancement | Cross-event query capability | Peter | üìã Planned | **HIGH** | **Mar 3, 2026** *(Phase 2)* | Extend chat actions to support cross-event queries; update router_prompt.py intent patterns for multi-event scenarios |
| PKA-001 | PKA Synthesis Agents | Phase 2+ launch (gates pending) | Peter | üìã Planned | **MEDIUM** | **Mar 3, 2026** *(Phase 2)* | Confirm agents are Phase 2 only; implement PKA blocking logic; add draft-only enforcement |

## Blocking Items for Phase 1 MVP Launch

### ‚úã INDIA MVP BLOCKERS (Code + Compliance)

**Code Work (Peter):**
1. **GOV-002**: Add `log_refusal()` function to telemetry
   - Minimal implementation: refusal_reason, query_context, handler_name
   - Emit to 1DS `copilot_interaction` event
   - Status: **CRITICAL** ‚Äî *Compliance sign-off requires evidence of logging capability*

2. **Basic Edit Tracking** (Optional for India, required for continuous compliance monitoring)
   - Add `log_edit_event()` function to telemetry
   - Track on feedback/thumbs-up/down actions
   - Status: **HIGH** ‚Äî *Deferred post-launch if Mike's frontend feedback actions not ready*

**Compliance/Process Work (Org Level ‚Äî Not Just Code):**
3. ‚úÖ **RAI Inventory Registration** ‚Äî *Must file project in Responsible AI Inventory with DOSA feature summary*
4. ‚úÖ **HR Legal Review** ‚Äî *Legal team sign-off on internal AI usage*
5. ‚úÖ **RAI Impact Assessment** ‚Äî *Complete impact assessment documenting fail-closed mitigations*
6. ‚úÖ **Privacy DPIA** ‚Äî *Data Privacy Impact Assessment for event abstracts, bookmarks, telemetry*
7. ‚úÖ **Accessibility Audit** ‚Äî *WCAG 2.1 AA compliance for chat UI + event pages*
8. ‚úÖ **Security Review** ‚Äî *Threat model, penetration testing, no P0/P1 issues*
9. ‚úÖ **SSPA Verification** ‚Äî *Confirm no external supplier data handling (Azure OpenAI is Microsoft-owned)*
10. ‚úÖ **Continuous Compliance Plan** ‚Äî *Document post-launch monitoring strategy*

### üö´ NOT BLOCKING INDIA (Defer to Phase 2)
- ‚ùå `governance_enforcer.py` with enforcement logic (fail-closed design already in architecture)
- ‚ùå Multi-event discovery enhancement
- ‚ùå Bookmark backend persistence *(Mike's scope)*
- ‚ùå PKA blocking logic *(already disabled by design)*
- ‚ùå Complex compliance dashboards

### ‚òÅÔ∏è AZURE AI FOUNDRY INFRASTRUCTURE (Must Complete Before Launch)

Based on the [Azure AI Foundry Resource Management Guide](./AZURE_AI_FOUNDRY_SETUP.md), the following operational requirements must be completed for India MVP security, compliance, and governance:

**Due by January 24, 2026:**

**Infrastructure & Networking (Platform Team):**
- [ ] Resource group created: `rg-msr-event-hub-ai-prod`
- [ ] Virtual Network configured with Zero Trust architecture
- [ ] Private Endpoints deployed for Azure OpenAI, Key Vault
- [ ] Network Security Groups with explicit HTTPS-only + deny-all default
- [ ] Private DNS Zones configured for service resolution

**Azure OpenAI & Model Management (Platform Team):**
- [ ] Azure OpenAI Service deployed (`aoai-msr-eventhub-prod`)
- [ ] Model deployments completed:
  - [ ] GPT-4 Turbo (10 TPM) for complex reasoning
  - [ ] GPT-3.5 Turbo (20 TPM) for general queries
  - [ ] Text-Embedding-Ada-002 (5 TPM) for semantic search
- [ ] Content filters configured (hate, violence, sexual, self-harm ‚Üí Medium severity)
- [ ] Public network access disabled (private endpoints only)

**Access Control & Identity (Platform Team):**
- [ ] Managed Identity created: `mi-msr-eventhub-ai`
- [ ] RBAC roles assigned:
  - [ ] Cognitive Services User (OpenAI access)
  - [ ] Machine Learning Workspace Contributor (AI Foundry)
  - [ ] Storage Blob Data Contributor (model artifacts)
  - [ ] Key Vault Secrets Officer (credential retrieval)
- [ ] Key Vault created with CMK encryption support
- [ ] Service Principal created for CI/CD (federated credentials)

**Security & Compliance (Security Team):**
- [ ] Conditional Access policies configured (MFA required, legacy auth blocked)
- [ ] Privileged Identity Management (PIM) enabled for role activation
- [ ] Customer-Managed Keys (CMK) enabled in Key Vault
- [ ] Diagnostic logging enabled (90-day retention)
- [ ] Audit trails configured for all secret access

**Monitoring & Governance (Observability Team):**
- [ ] Application Insights deployed (`ai-msr-eventhub-monitoring`)
- [ ] Custom metrics configured:
  - [ ] Model inference latency (p99 < 2 sec alert)
  - [ ] Token usage tracking (daily cost report)
  - [ ] Refusal rate monitoring (< 5% threshold)
  - [ ] Error rate monitoring (< 0.1% threshold)
- [ ] Cost alerts configured (daily/monthly budgets)
- [ ] Compliance audit logging enabled

**Documentation & Runbooks:**
- [ ] [AZURE_AI_FOUNDRY_SETUP.md](./AZURE_AI_FOUNDRY_SETUP.md) created with full setup procedures
- [ ] Incident response playbook documented
- [ ] Cost optimization baseline established
- [ ] Troubleshooting guide created

**Reference:** See [AZURE_AI_FOUNDRY_SETUP.md](./AZURE_AI_FOUNDRY_SETUP.md) for detailed setup procedures, CLI commands, and validation steps.

---

## ‚úÖ ACTUAL STATE (Code Review Results)

### Already Implemented ‚úÖ

| Story ID | Feature | Current Status | Location | Notes |
|---|---|---|---|---|
| - | **15 Chat Actions** | ‚úÖ Complete | `src/api/actions/` | browse, filter, search, navigation, experiences handlers all registered |
| - | **Action Registry** | ‚úÖ Complete | `src/api/actions/base.py` | Full decorator-based handler registration working |
| - | **Telemetry Framework** | ‚úÖ Complete | `src/observability/telemetry.py` | 1DS initialized, `track_event()`, `track_model_inference()`, `track_user_feedback()`, `track_repository_operation()` all working |
| - | **Model Inference Tracking** | ‚úÖ Complete | `src/api/chat_routes.py` | Token count, latency, success/error logged on every inference |
| - | **Streaming Responses** | ‚úÖ Complete | `src/api/chat_routes.py` | Azure OpenAI streaming integrated, `_forward_stream()` functional |
| - | **Event Data Layer** | ‚úÖ Complete | `src/core/`, `src/storage/` | Event, Session, Project repositories with CRUD operations |
| - | **Hourly Agenda Action** | ‚úÖ Complete | `src/api/actions/experiences/handlers.py` | `HourlyAgendaHandler` fully implemented |
| - | **Presenter Carousel** | ‚úÖ Complete | `src/api/actions/experiences/handlers.py` | `PresenterCarouselHandler` fully implemented |

### Partial/Stub Implementation ‚è≥

| Story ID | Feature | Current Status | Location | What's Missing |
|---|---|---|---|---|
| BOOKMARK-001 | Bookmark Action | ‚è≥ Stub | `src/api/actions/experiences/handlers.py` | `BookmarkHandler` only acknowledges; **NO database persistence** - just returns placeholder message |
| TELEMETRY-001 | Governance Metrics in 1DS | ‚è≥ Partial | `src/observability/telemetry.py` | Framework exists but NO `log_refusal()` or `log_edit_event()` functions yet |
| GOV-001 | DOSA Enforcement | ‚ùå Missing | - | NO `governance_enforcer.py` file; NO citation validation; NO inference blocking logic |
| GOV-002 | Refusal Tracking | ‚ùå Missing | - | NO `log_refusal()` function; NO compliance telemetry events |
| GOV-003 | Edit Percentage Logging | ‚ùå Missing | - | NO `log_edit_event()` function; NO edit vs. accept tracking |
| DISCOVERY-001 | Multi-Event Queries | ‚è≥ Partial | `src/api/query_router.py`, `router_prompt.py` | Router exists; intent patterns exist but not optimized for cross-event scenarios |
| PKA-001 | PKA Synthesis Agents | ‚è≥ Partial | `src/agents/`, `src/workflows/project_compilation.py` | Agents exist but Phase 2 blocking not fully enforced |

### NOT OWNED BY YOU (Frontend/Persistence - Mike's Scope)

| Story ID | Feature | Status | Owner | Notes |
|---|---|---|---|---|
| BOOKMARK-001 | Bookmark Persistence | To Be Implemented | **Mike** | Backend table creation, CRUD endpoints, frontend bookmark UI |
| - | Frontend Chat UI | - | **Mike** | React components, adaptive card rendering, bookmark button |
| - | Post-Event Access | - | **Mike** | Frontend state management for saved bookmarks |

---

## üìã FOCUSED IMPLEMENTATION PLAN FOR INDIA MVP

### Phase: NOW (Week of Jan 15-22, 2026)

#### 1. **Add Refusal Logging to Telemetry** *(Peter, 2-3 hours)*
   
**File**: `src/observability/telemetry.py`

Add these functions after `track_user_feedback()`:

```python
def log_refusal(
    refusal_reason: str,
    query_context: str,
    handler_name: str,
    user_id: Optional[str] = None,
    conversation_id: Optional[str] = None
) -> None:
    """
    Log AI refusal for compliance tracking.
    
    Args:
        refusal_reason: Why the query was refused (e.g., 'no_citations', 'out_of_scope')
        query_context: The original user query (first 200 chars)
        handler_name: Handler that refused (e.g., 'search_handler')
        user_id: Optional user identifier
        conversation_id: Optional conversation context
    """
    track_event(
        "copilot_refusal",  # DOSA compliance metric
        properties={
            "refusal_reason": refusal_reason,
            "query_context": query_context[:200],  # Truncate PII
            "handler_name": handler_name,
            "user_id": user_id or "anonymous",
            "conversation_id": conversation_id or "N/A"
        }
    )

def log_edit_event(
    conversation_id: str,
    message_id: str,
    was_edited: bool,
    user_id: Optional[str] = None
) -> None:
    """
    Log edit/accept actions for compliance metrics.
    
    Args:
        conversation_id: Conversation identifier
        message_id: Message identifier
        was_edited: True if user edited, False if accepted
        user_id: Optional user identifier
    """
    track_event(
        "copilot_edit_action",  # Human-in-loop metric
        properties={
            "conversation_id": conversation_id,
            "message_id": message_id,
            "action": "edit" if was_edited else "accept",
            "user_id": user_id or "anonymous"
        }
    )
```

**Acceptance**: Telemetry functions exist and emit to 1DS `copilot_refusal` and `copilot_edit_action` events.

---

#### 2. **Wire Refusal Logging into Chat Routes** *(Peter, 1-2 hours)*

**File**: `src/api/chat_routes.py`

After the import of telemetry functions (line 24-25), add refusal handling in the action dispatch logic. When an action handler returns empty or None response, call:

```python
log_refusal(
    refusal_reason="insufficient_citations",
    query_context=request_payload.get("query", "")[:200],
    handler_name=action_name,
    user_id=context.user_id if context else None
)
```

**Acceptance**: Refusals are logged with context and emitted to 1DS.

---

#### 3. **Document Fail-Closed Design in RAI Assessment** *(Peter + Compliance Owner, 1-2 hours)*

**Deliverable**: Update or create the DOSA section of the RAI Impact Assessment document:

Key points to document:
- ‚úÖ DOSA is discovery-only (no synthesis or inference)
- ‚úÖ All responses sourced from event abstracts and approved content
- ‚úÖ Fail-closed: returns only explicit claims with citations
- ‚úÖ Refusal logging implemented (copilot_refusal events to 1DS)
- ‚úÖ No PKA outputs exposed to attendees (blocked by design)
- ‚úÖ Continuous monitoring plan: track refusal rate, edits, feedback

**Acceptance**: RAI Assessment complete with mitigations documented.

---

### Phase: POST-INDIA (Feb-Mar 2026, Phase 2)

These can launch after India MVP if time permits or are lower priority:

- **GOV-001**: Full `governance_enforcer.py` with citation validation middleware
- **Advanced Edit Tracking**: Create compliance dashboard aggregating edit %
- **Multi-Event Discovery**: Enhance router for cross-event queries
- **Bookmark Persistence**: Mike completes backend + frontend integration

---

## ‚úÖ COMPLIANCE STATUS SNAPSHOT

| Gate | Status | Owner | Notes |
|---|---|---|---|
| RAI Inventory | ‚è≥ In Progress | [TBD] | Must register DOSA feature in Microsoft RAI Inventory |
| HR Legal Review | ‚è≥ In Progress | [TBD] | Legal team sign-off on internal AI usage |
| RAI Impact Assessment | ‚è≥ In Progress | Peter + Compliance | Document fail-closed design + refusal logging |
| Privacy DPIA | ‚è≥ In Progress | [TBD] | Event abstracts, bookmarks, telemetry handling |
| Accessibility (WCAG 2.1 AA) | ‚è≥ In Progress | [TBD] | Chat UI, event pages keyboard + screen-reader tested |
| Security Review | ‚è≥ In Progress | [TBD] | Threat model, no P0/P1 issues |
| SSPA Verification | ‚è≥ In Progress | [TBD] | Confirm no external supplier data handling |
| Continuous Compliance Plan | ‚è≥ Draft | Peter | Document refusal monitoring, edit %, incident escalation |

**Blocking Launch?** Only if compliance sign-offs not in flight. Coding work (refusal logging) is trivial.

---

## üîÄ CODE vs. COMPLIANCE CROSS-REFERENCE

| What | Code Status | Compliance Status | India Blocking? |
|---|---|---|---|
| DOSA Chat (15 actions) | ‚úÖ Done | ‚úÖ Mitigations documented in RAI | ‚úÖ Yes (launch blocker) |
| Fail-Closed Design | ‚úÖ Built into architecture | ‚è≥ Awaiting RAI Assessment | ‚ùå No (design doc, not code) |
| Refusal Logging | ‚è≥ Minimal logging needed | ‚è≥ Awaiting continuous compliance plan | ‚è≥ CRITICAL code work |
| Edit Tracking | ‚ùå Not started | ‚è≥ Optional for MVP | ‚ùå No (Phase 2) |
| Bookmark Persistence | ‚ùå Stub only | N/A (Mike's scope) | ‚ùå No (functional stub is OK) |
| PKA Blocking | ‚è≥ Partial (agents exist but exposed) | ‚úÖ Already blocked from attendees | ‚ùå No (design handles it) |
| Governance Enforcer | ‚ùå Not started | ‚è≥ Architectural docs written | ‚ùå No (design already enforces) |

**Key Insight**: The DOSA "fail-closed" governance is **already built into the architecture** (returns only citations). The code work is mainly **telemetry/monitoring**, not enforcement.

---

## üö¶ RISK ASSESSMENT

| Risk | Impact | Mitigation | Status |
|---|---|---|---|
| Compliance sign-offs slip | üî¥ Blocks India launch | Start process immediately; RAI lead owns timeline | ‚è≥ In flight |
| Refusal logging code not ready | üü° Minor ‚Äî can add post-launch | Implementation is trivial (2-3 hours) | ‚úÖ Mitigated |
| Accessibility audit incomplete | üî¥ Blocks launch (per COMPLIANCE.md) | Engage APEX team now for chat UI review | ‚è≥ In flight |
| Bookmark feature missing | üü° Minor ‚Äî stub acceptable for MVP | Mike handling; not a chat logic blocker | ‚úÖ Mitigated |
| PKA exposure to attendees | üü¢ None ‚Äî already prevented by design | Confirm `ProjectSynthesisHandler` returns "coming soon" message | ‚úÖ Verified |

---

## ÔøΩ Production Readiness Gap: Microsoft Org Requirements

Based on the BRD, COMPLIANCE.md, and Responsible AI framework, here's what's **missing for full production readiness** beyond the code:

### üî¥ CRITICAL (Blocks Launch)

| Gap | Why It Matters | Owner | Effort | Status |
|---|---|---|---|---|
| **RAI Inventory Registration** | Microsoft requires all AI features to be registered in the Responsible AI Inventory. DOSA cannot launch without this entry. | RAI Champs / Compliance | 1-2 days | ‚è≥ In flight |
| **RAI Impact Assessment** | Formal analysis of risks, mitigations, and governance design. Must document fail-closed architecture, refusal logging, and monitoring plan. | Peter + Compliance Lead | 3-5 days | ‚è≥ In flight |
| **HR Legal Review Sign-Off** | Internal legal must approve AI usage for employees. Covers policy alignment, liability, and employee consent. | Legal Team | 3-5 days | ‚è≥ In flight |
| **Privacy DPIA** | Data Privacy Impact Assessment for event abstracts, bookmarks, telemetry. Must document data minimization, storage, retention, and employee rights. | Privacy Champion | 3-5 days | ‚è≥ In flight |
| **Accessibility Audit (WCAG 2.1 AA)** | Chat UI, event pages, and admin tools must be keyboard-navigable and screen-reader compatible. Microsoft compliance is mandatory. | Accessibility Team (APEX) | 5-7 days | ‚è≥ In flight |
| **Security Review & Threat Model** | Penetration testing, code review, auth verification, no P0/P1 issues before launch. Documents security architecture and sign-off. | Security Team / Azure Security | 5-10 days | ‚è≥ In flight |

### üü° HIGH (Needed for Scale)

| Gap | Why It Matters | Owner | Effort | Status |
|---|---|---|---|---|
| **Continuous Compliance Monitoring Plan** | Post-launch: monthly refusal rate review, edit % tracking, incident escalation, quarterly RAI check-ins. Ensures ongoing compliance as AI is used. | Peter + Compliance Lead | 2-3 days | ‚è≥ Draft started |
| **SSPA Verification** | If any supplier data handling (likely NO in your case‚ÄîAzure OpenAI is Microsoft-owned). Document that no external services touch personal data. | SSPA Program Manager | 1-2 days | ‚úÖ Likely clear |
| **Incident Response & Escalation Plan** | Procedure for handling AI safety incidents (e.g., DOSA returns unsupported answer, refusal rate spikes, user data breach). | Security + Compliance | 1-2 days | ‚ùå Missing |
| **User Disclosure & Transparency** | Help text, tooltips, or documentation informing attendees that chat is "AI-powered" and answers are from event content only. | Product / UX | 1 day | ‚ùå Missing |
| **Admin Training & Governance** | Organizers must understand DOSA scope (discovery-only, no synthesis), PKA phase (Phase 2+), and compliance constraints. | Product Ops | 1-2 days | ‚ùå Missing |

### üü¢ IMPORTANT (For Durability)

| Gap | Why It Matters | Owner | Effort | Status |
|---|---|---|---|---|
| **Runbook & Operational Playbook** | How to handle common issues: high latency, content not appearing in search, user data privacy requests, compliance monitoring. | DevOps / Support | 3-5 days | ‚è≥ Partial (see DEPLOYMENT_RUNBOOK.md) |
| **Metrics Dashboard** | 1DS dashboard for ops/compliance: refusal rate, edit %, latency, error rate, user feedback, cost. Required for continuous compliance. | Analytics / DevOps | 3-5 days | ‚ùå Missing |
| **Rollback & Incident Response** | Documented process for rolling back bad deployments, handling data incidents, communicating to stakeholders. | DevOps | 1-2 days | ‚è≥ Partial |
| **Data Retention & Deletion Policy** | How long do bookmarks, conversation history, and telemetry stay? How do users request deletion? Satisfies privacy regulations. | Privacy Champion | 1-2 days | ‚ùå Missing |
| **Documentation for Stakeholders** | Help docs for attendees, admins, presenters. Explains what the chat can/cannot do, privacy implications, how to report issues. | Product / Documentation | 3-5 days | ‚ùå Missing |

---

## üìä Production Readiness Summary

**Current State:**
- ‚úÖ Backend code: 100% (15 actions, streaming, telemetry, auth)
- ‚úÖ Data layer: 100% (event/session/project repos, CRUD operations)
- ‚úÖ AI integration: 100% (Azure OpenAI, Foundry agents)
- ‚ùå Compliance framework: 10% (code logging exists, sign-offs pending)
- ‚ùå Operational readiness: 30% (runbook partial, dashboards missing, training missing)
- ‚ùå User documentation: 0% (no help text, no disclosure)

**What Will Make It "Production-Ready for Microsoft Org":**

1. **Compliance gates signed off** (RAI Inventory, Legal, Privacy, Accessibility, Security)
   - This is the biggest blocker; not code, but process/governance
   - Estimated 2-3 weeks to collect all sign-offs (parallel workstreams)

2. **Compliance monitoring dashboard** (refusal rate, edit %, latency, errors)
   - Ops team needs visibility into DOSA health
   - Estimated 3-5 days to build in App Insights / PowerBI

3. **User disclosure** (help text, tooltips, documentation)
   - "This is AI-powered discovery. Answers come from event content."
   - Estimated 1-2 days to write + review

4. **Admin training & documentation**
   - Organizers need to understand constraints (DOSA discovery-only, PKA phase 2+)
   - Estimated 2-3 days to create training deck + runbook updates

5. **Incident response playbook**
   - How to handle refusal spikes, content gaps, user issues, data requests
   - Estimated 1-2 days

**Estimated Timeline to "Production-Ready":**
- **India MVP Launch**: Jan 24, 2026 (code + compliance sign-offs in progress)
- **Full Production-Ready**: Feb 15-28, 2026 (compliance gates cleared + dashboards + docs + training)

---

## üéØ Recommendation

For **MSR India TAB MVP launch (Jan 24)**:
- ‚úÖ Have compliance sign-offs **in flight** (not all need to be complete, but all workstreams started)
- ‚úÖ Have refusal logging **code deployed** (minimal, but functional)
- ‚úÖ Have a documented **monitoring plan** (even if dashboard not built yet)
- ‚úÖ Have basic **user disclosure** (help text on chat UI)

For **Full Production-Ready (Feb-Mar)**:
- ‚úÖ All compliance gates **signed off**
- ‚úÖ Compliance monitoring **dashboard live**
- ‚úÖ Admin training & **operational runbook** complete
- ‚úÖ Incident response **procedures documented**

**Code (Peter):**
- [ ] Add `log_refusal()` function to telemetry.py
- [ ] Add `log_edit_event()` function to telemetry.py
- [ ] Wire refusal logging into `chat_routes.py`
- [ ] Test: emit refusal event to local 1DS endpoint

**Compliance/Process (Cross-functional):**
- [ ] File RAI Inventory entry (Responsible AI Champs)
- [ ] Complete RAI Impact Assessment (Peter + Compliance Lead)
  - Document fail-closed design
  - Document refusal logging implementation
  - Document continuous monitoring plan
- [ ] HR Legal Review sign-off
- [ ] Privacy DPIA sign-off
- [ ] Accessibility audit completion (WCAG 2.1 AA for chat + event pages)
- [ ] Security review completion (threat model, pen testing)
- [ ] SSPA verification (Azure OpenAI ‚Äî Microsoft-owned ‚úÖ)

**Launch Readiness:**
- [ ] All compliance sign-offs collected
- [ ] Refusal logging emitting to 1DS
- [ ] Pre-event load test completed
- [ ] Documentation updated (help text for users: "This is AI-powered discovery. All answers are from event content.")